{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hackthon - 21/11/2024\n",
    "\n",
    "## Objetivo: \n",
    "\n",
    "desafio de classificação em um conjunto de dados de características extraídas de imagens. As imagens são provenientes de um exame de microscopia com o objetivo de encontrar células saudáveis e células concerígenas;\n",
    "\n",
    "## Entrega: \n",
    "\n",
    "modelo treinado no formato da biblioteca pickle e notebook;\n",
    "Prazo: até 12:00 de 22/11/2024;\n",
    "\n",
    "## Pontuação:\n",
    "\n",
    "- 1 ponto: >= 80% de acerto;\n",
    "- 0,5 ponto extra: equipe com o melhor resultado;\n",
    "- 0,5 ponto extra: equipe com o melhor código (escrita, comentários, etc);\n",
    "\n",
    "# Regras\n",
    "\n",
    "- Pode consultar o que quiser;\n",
    "\n",
    "## Obrigatório:\n",
    "- K-fold (random_state = 19)\n",
    "- Métrica Kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.linear_model import RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0011806</th>\n",
       "      <th>0.0012137</th>\n",
       "      <th>0.001208</th>\n",
       "      <th>0.0012018</th>\n",
       "      <th>1071.2</th>\n",
       "      <th>1046.8</th>\n",
       "      <th>1048.8</th>\n",
       "      <th>1055</th>\n",
       "      <th>1180.7</th>\n",
       "      <th>1552.3</th>\n",
       "      <th>...</th>\n",
       "      <th>0.0046729</th>\n",
       "      <th>778.89</th>\n",
       "      <th>795.98</th>\n",
       "      <th>788.88</th>\n",
       "      <th>839.12</th>\n",
       "      <th>4806.8</th>\n",
       "      <th>3260.5</th>\n",
       "      <th>3810</th>\n",
       "      <th>2836.1</th>\n",
       "      <th>-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001107</td>\n",
       "      <td>0.001119</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>1039.50</td>\n",
       "      <td>1033.20</td>\n",
       "      <td>1037.90</td>\n",
       "      <td>1042.00</td>\n",
       "      <td>2061.90</td>\n",
       "      <td>2842.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004115</td>\n",
       "      <td>690.72</td>\n",
       "      <td>744.43</td>\n",
       "      <td>709.54</td>\n",
       "      <td>766.11</td>\n",
       "      <td>5627.8</td>\n",
       "      <td>3720.7</td>\n",
       "      <td>5336.2</td>\n",
       "      <td>3671.1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000838</td>\n",
       "      <td>0.000817</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>1474.20</td>\n",
       "      <td>1506.50</td>\n",
       "      <td>1512.10</td>\n",
       "      <td>1509.20</td>\n",
       "      <td>3152.70</td>\n",
       "      <td>4917.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003754</td>\n",
       "      <td>871.63</td>\n",
       "      <td>1030.40</td>\n",
       "      <td>1000.50</td>\n",
       "      <td>1020.10</td>\n",
       "      <td>13398.0</td>\n",
       "      <td>7915.7</td>\n",
       "      <td>11760.0</td>\n",
       "      <td>8232.1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000959</td>\n",
       "      <td>0.000957</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>0.000958</td>\n",
       "      <td>1173.50</td>\n",
       "      <td>1181.10</td>\n",
       "      <td>1182.60</td>\n",
       "      <td>1181.20</td>\n",
       "      <td>989.97</td>\n",
       "      <td>1348.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003669</td>\n",
       "      <td>761.77</td>\n",
       "      <td>836.36</td>\n",
       "      <td>800.78</td>\n",
       "      <td>846.97</td>\n",
       "      <td>7517.2</td>\n",
       "      <td>4942.6</td>\n",
       "      <td>6486.0</td>\n",
       "      <td>4416.6</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001199</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.001212</td>\n",
       "      <td>0.001218</td>\n",
       "      <td>998.09</td>\n",
       "      <td>1001.80</td>\n",
       "      <td>989.75</td>\n",
       "      <td>984.42</td>\n",
       "      <td>930.80</td>\n",
       "      <td>1843.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004436</td>\n",
       "      <td>641.78</td>\n",
       "      <td>785.93</td>\n",
       "      <td>751.50</td>\n",
       "      <td>760.29</td>\n",
       "      <td>6421.8</td>\n",
       "      <td>2951.4</td>\n",
       "      <td>3344.0</td>\n",
       "      <td>2882.6</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001475</td>\n",
       "      <td>0.001478</td>\n",
       "      <td>0.001462</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>907.20</td>\n",
       "      <td>910.03</td>\n",
       "      <td>921.85</td>\n",
       "      <td>900.22</td>\n",
       "      <td>955.55</td>\n",
       "      <td>1267.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008193</td>\n",
       "      <td>665.58</td>\n",
       "      <td>725.56</td>\n",
       "      <td>684.40</td>\n",
       "      <td>712.31</td>\n",
       "      <td>4015.4</td>\n",
       "      <td>2846.9</td>\n",
       "      <td>3709.8</td>\n",
       "      <td>2642.7</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>0.001524</td>\n",
       "      <td>0.001544</td>\n",
       "      <td>0.001554</td>\n",
       "      <td>0.001533</td>\n",
       "      <td>771.82</td>\n",
       "      <td>765.06</td>\n",
       "      <td>760.72</td>\n",
       "      <td>767.49</td>\n",
       "      <td>1757.30</td>\n",
       "      <td>2667.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009052</td>\n",
       "      <td>449.22</td>\n",
       "      <td>505.74</td>\n",
       "      <td>481.86</td>\n",
       "      <td>525.14</td>\n",
       "      <td>6456.4</td>\n",
       "      <td>4333.4</td>\n",
       "      <td>5510.5</td>\n",
       "      <td>3652.4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>0.002081</td>\n",
       "      <td>0.002125</td>\n",
       "      <td>0.002143</td>\n",
       "      <td>0.002136</td>\n",
       "      <td>717.41</td>\n",
       "      <td>706.27</td>\n",
       "      <td>692.82</td>\n",
       "      <td>697.34</td>\n",
       "      <td>1442.90</td>\n",
       "      <td>1588.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008687</td>\n",
       "      <td>605.75</td>\n",
       "      <td>603.61</td>\n",
       "      <td>527.33</td>\n",
       "      <td>604.96</td>\n",
       "      <td>1930.2</td>\n",
       "      <td>1742.7</td>\n",
       "      <td>2547.4</td>\n",
       "      <td>1486.1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>0.001254</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.001270</td>\n",
       "      <td>0.001281</td>\n",
       "      <td>1184.30</td>\n",
       "      <td>1209.10</td>\n",
       "      <td>1198.60</td>\n",
       "      <td>1190.80</td>\n",
       "      <td>2033.90</td>\n",
       "      <td>2822.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004550</td>\n",
       "      <td>829.15</td>\n",
       "      <td>925.68</td>\n",
       "      <td>873.47</td>\n",
       "      <td>902.69</td>\n",
       "      <td>6960.8</td>\n",
       "      <td>4208.7</td>\n",
       "      <td>5503.9</td>\n",
       "      <td>4354.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>0.001481</td>\n",
       "      <td>0.001492</td>\n",
       "      <td>0.001491</td>\n",
       "      <td>0.001518</td>\n",
       "      <td>888.70</td>\n",
       "      <td>883.39</td>\n",
       "      <td>877.48</td>\n",
       "      <td>866.00</td>\n",
       "      <td>1548.80</td>\n",
       "      <td>2111.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004107</td>\n",
       "      <td>682.09</td>\n",
       "      <td>734.07</td>\n",
       "      <td>688.15</td>\n",
       "      <td>697.72</td>\n",
       "      <td>3022.3</td>\n",
       "      <td>2036.6</td>\n",
       "      <td>2609.3</td>\n",
       "      <td>2124.5</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>0.001311</td>\n",
       "      <td>0.001322</td>\n",
       "      <td>0.001324</td>\n",
       "      <td>0.001325</td>\n",
       "      <td>1223.90</td>\n",
       "      <td>1234.90</td>\n",
       "      <td>1235.60</td>\n",
       "      <td>1238.50</td>\n",
       "      <td>2221.90</td>\n",
       "      <td>3128.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004696</td>\n",
       "      <td>892.92</td>\n",
       "      <td>987.35</td>\n",
       "      <td>924.71</td>\n",
       "      <td>951.54</td>\n",
       "      <td>5850.2</td>\n",
       "      <td>3591.9</td>\n",
       "      <td>4988.3</td>\n",
       "      <td>4083.6</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>916 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0.0011806  0.0012137  0.001208  0.0012018   1071.2   1046.8   1048.8  \\\n",
       "0     0.001107   0.001119  0.001116   0.001109  1039.50  1033.20  1037.90   \n",
       "1     0.000838   0.000817  0.000813   0.000816  1474.20  1506.50  1512.10   \n",
       "2     0.000959   0.000957  0.000959   0.000958  1173.50  1181.10  1182.60   \n",
       "3     0.001199   0.001197  0.001212   0.001218   998.09  1001.80   989.75   \n",
       "4     0.001475   0.001478  0.001462   0.001484   907.20   910.03   921.85   \n",
       "..         ...        ...       ...        ...      ...      ...      ...   \n",
       "911   0.001524   0.001544  0.001554   0.001533   771.82   765.06   760.72   \n",
       "912   0.002081   0.002125  0.002143   0.002136   717.41   706.27   692.82   \n",
       "913   0.001254   0.001253  0.001270   0.001281  1184.30  1209.10  1198.60   \n",
       "914   0.001481   0.001492  0.001491   0.001518   888.70   883.39   877.48   \n",
       "915   0.001311   0.001322  0.001324   0.001325  1223.90  1234.90  1235.60   \n",
       "\n",
       "        1055   1180.7  1552.3  ...  0.0046729  778.89   795.98   788.88  \\\n",
       "0    1042.00  2061.90  2842.8  ...   0.004115  690.72   744.43   709.54   \n",
       "1    1509.20  3152.70  4917.1  ...   0.003754  871.63  1030.40  1000.50   \n",
       "2    1181.20   989.97  1348.5  ...   0.003669  761.77   836.36   800.78   \n",
       "3     984.42   930.80  1843.0  ...   0.004436  641.78   785.93   751.50   \n",
       "4     900.22   955.55  1267.9  ...   0.008193  665.58   725.56   684.40   \n",
       "..       ...      ...     ...  ...        ...     ...      ...      ...   \n",
       "911   767.49  1757.30  2667.9  ...   0.009052  449.22   505.74   481.86   \n",
       "912   697.34  1442.90  1588.2  ...   0.008687  605.75   603.61   527.33   \n",
       "913  1190.80  2033.90  2822.1  ...   0.004550  829.15   925.68   873.47   \n",
       "914   866.00  1548.80  2111.8  ...   0.004107  682.09   734.07   688.15   \n",
       "915  1238.50  2221.90  3128.7  ...   0.004696  892.92   987.35   924.71   \n",
       "\n",
       "      839.12   4806.8  3260.5     3810  2836.1  -1  \n",
       "0     766.11   5627.8  3720.7   5336.2  3671.1  -1  \n",
       "1    1020.10  13398.0  7915.7  11760.0  8232.1  -1  \n",
       "2     846.97   7517.2  4942.6   6486.0  4416.6  -1  \n",
       "3     760.29   6421.8  2951.4   3344.0  2882.6  -1  \n",
       "4     712.31   4015.4  2846.9   3709.8  2642.7  -1  \n",
       "..       ...      ...     ...      ...     ...  ..  \n",
       "911   525.14   6456.4  4333.4   5510.5  3652.4  -1  \n",
       "912   604.96   1930.2  1742.7   2547.4  1486.1  -1  \n",
       "913   902.69   6960.8  4208.7   5503.9  4354.0  -1  \n",
       "914   697.72   3022.3  2036.6   2609.3  2124.5  -1  \n",
       "915   951.54   5850.2  3591.9   4988.3  4083.6  -1  \n",
       "\n",
       "[916 rows x 45 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"GLRLM_cyto.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     -1\n",
       "1     -1\n",
       "2     -1\n",
       "3     -1\n",
       "4     -1\n",
       "      ..\n",
       "911   -1\n",
       "912   -1\n",
       "913   -1\n",
       "914   -1\n",
       "915   -1\n",
       "Name: -1, Length: 916, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.iloc[:, -1]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "911    0\n",
       "912    0\n",
       "913    0\n",
       "914    0\n",
       "915    0\n",
       "Name: -1, Length: 916, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.map({-1: 0, 1: 1})\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1\n",
       "0    674\n",
       "1    242\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1\n",
       "0    674\n",
       "1    242\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0011806</th>\n",
       "      <th>0.0012137</th>\n",
       "      <th>0.001208</th>\n",
       "      <th>0.0012018</th>\n",
       "      <th>1071.2</th>\n",
       "      <th>1046.8</th>\n",
       "      <th>1048.8</th>\n",
       "      <th>1055</th>\n",
       "      <th>1180.7</th>\n",
       "      <th>1552.3</th>\n",
       "      <th>...</th>\n",
       "      <th>0.0061704</th>\n",
       "      <th>0.0046729</th>\n",
       "      <th>778.89</th>\n",
       "      <th>795.98</th>\n",
       "      <th>788.88</th>\n",
       "      <th>839.12</th>\n",
       "      <th>4806.8</th>\n",
       "      <th>3260.5</th>\n",
       "      <th>3810</th>\n",
       "      <th>2836.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001107</td>\n",
       "      <td>0.001119</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>1039.50</td>\n",
       "      <td>1033.20</td>\n",
       "      <td>1037.90</td>\n",
       "      <td>1042.00</td>\n",
       "      <td>2061.90</td>\n",
       "      <td>2842.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005960</td>\n",
       "      <td>0.004115</td>\n",
       "      <td>690.72</td>\n",
       "      <td>744.43</td>\n",
       "      <td>709.54</td>\n",
       "      <td>766.11</td>\n",
       "      <td>5627.8</td>\n",
       "      <td>3720.7</td>\n",
       "      <td>5336.2</td>\n",
       "      <td>3671.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000838</td>\n",
       "      <td>0.000817</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>1474.20</td>\n",
       "      <td>1506.50</td>\n",
       "      <td>1512.10</td>\n",
       "      <td>1509.20</td>\n",
       "      <td>3152.70</td>\n",
       "      <td>4917.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005271</td>\n",
       "      <td>0.003754</td>\n",
       "      <td>871.63</td>\n",
       "      <td>1030.40</td>\n",
       "      <td>1000.50</td>\n",
       "      <td>1020.10</td>\n",
       "      <td>13398.0</td>\n",
       "      <td>7915.7</td>\n",
       "      <td>11760.0</td>\n",
       "      <td>8232.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000959</td>\n",
       "      <td>0.000957</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>0.000958</td>\n",
       "      <td>1173.50</td>\n",
       "      <td>1181.10</td>\n",
       "      <td>1182.60</td>\n",
       "      <td>1181.20</td>\n",
       "      <td>989.97</td>\n",
       "      <td>1348.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005446</td>\n",
       "      <td>0.003669</td>\n",
       "      <td>761.77</td>\n",
       "      <td>836.36</td>\n",
       "      <td>800.78</td>\n",
       "      <td>846.97</td>\n",
       "      <td>7517.2</td>\n",
       "      <td>4942.6</td>\n",
       "      <td>6486.0</td>\n",
       "      <td>4416.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001199</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.001212</td>\n",
       "      <td>0.001218</td>\n",
       "      <td>998.09</td>\n",
       "      <td>1001.80</td>\n",
       "      <td>989.75</td>\n",
       "      <td>984.42</td>\n",
       "      <td>930.80</td>\n",
       "      <td>1843.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005279</td>\n",
       "      <td>0.004436</td>\n",
       "      <td>641.78</td>\n",
       "      <td>785.93</td>\n",
       "      <td>751.50</td>\n",
       "      <td>760.29</td>\n",
       "      <td>6421.8</td>\n",
       "      <td>2951.4</td>\n",
       "      <td>3344.0</td>\n",
       "      <td>2882.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001475</td>\n",
       "      <td>0.001478</td>\n",
       "      <td>0.001462</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>907.20</td>\n",
       "      <td>910.03</td>\n",
       "      <td>921.85</td>\n",
       "      <td>900.22</td>\n",
       "      <td>955.55</td>\n",
       "      <td>1267.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012025</td>\n",
       "      <td>0.008193</td>\n",
       "      <td>665.58</td>\n",
       "      <td>725.56</td>\n",
       "      <td>684.40</td>\n",
       "      <td>712.31</td>\n",
       "      <td>4015.4</td>\n",
       "      <td>2846.9</td>\n",
       "      <td>3709.8</td>\n",
       "      <td>2642.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>0.001524</td>\n",
       "      <td>0.001544</td>\n",
       "      <td>0.001554</td>\n",
       "      <td>0.001533</td>\n",
       "      <td>771.82</td>\n",
       "      <td>765.06</td>\n",
       "      <td>760.72</td>\n",
       "      <td>767.49</td>\n",
       "      <td>1757.30</td>\n",
       "      <td>2667.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013590</td>\n",
       "      <td>0.009052</td>\n",
       "      <td>449.22</td>\n",
       "      <td>505.74</td>\n",
       "      <td>481.86</td>\n",
       "      <td>525.14</td>\n",
       "      <td>6456.4</td>\n",
       "      <td>4333.4</td>\n",
       "      <td>5510.5</td>\n",
       "      <td>3652.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>0.002081</td>\n",
       "      <td>0.002125</td>\n",
       "      <td>0.002143</td>\n",
       "      <td>0.002136</td>\n",
       "      <td>717.41</td>\n",
       "      <td>706.27</td>\n",
       "      <td>692.82</td>\n",
       "      <td>697.34</td>\n",
       "      <td>1442.90</td>\n",
       "      <td>1588.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015723</td>\n",
       "      <td>0.008687</td>\n",
       "      <td>605.75</td>\n",
       "      <td>603.61</td>\n",
       "      <td>527.33</td>\n",
       "      <td>604.96</td>\n",
       "      <td>1930.2</td>\n",
       "      <td>1742.7</td>\n",
       "      <td>2547.4</td>\n",
       "      <td>1486.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>0.001254</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.001270</td>\n",
       "      <td>0.001281</td>\n",
       "      <td>1184.30</td>\n",
       "      <td>1209.10</td>\n",
       "      <td>1198.60</td>\n",
       "      <td>1190.80</td>\n",
       "      <td>2033.90</td>\n",
       "      <td>2822.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006287</td>\n",
       "      <td>0.004550</td>\n",
       "      <td>829.15</td>\n",
       "      <td>925.68</td>\n",
       "      <td>873.47</td>\n",
       "      <td>902.69</td>\n",
       "      <td>6960.8</td>\n",
       "      <td>4208.7</td>\n",
       "      <td>5503.9</td>\n",
       "      <td>4354.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>0.001481</td>\n",
       "      <td>0.001492</td>\n",
       "      <td>0.001491</td>\n",
       "      <td>0.001518</td>\n",
       "      <td>888.70</td>\n",
       "      <td>883.39</td>\n",
       "      <td>877.48</td>\n",
       "      <td>866.00</td>\n",
       "      <td>1548.80</td>\n",
       "      <td>2111.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005301</td>\n",
       "      <td>0.004107</td>\n",
       "      <td>682.09</td>\n",
       "      <td>734.07</td>\n",
       "      <td>688.15</td>\n",
       "      <td>697.72</td>\n",
       "      <td>3022.3</td>\n",
       "      <td>2036.6</td>\n",
       "      <td>2609.3</td>\n",
       "      <td>2124.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>0.001311</td>\n",
       "      <td>0.001322</td>\n",
       "      <td>0.001324</td>\n",
       "      <td>0.001325</td>\n",
       "      <td>1223.90</td>\n",
       "      <td>1234.90</td>\n",
       "      <td>1235.60</td>\n",
       "      <td>1238.50</td>\n",
       "      <td>2221.90</td>\n",
       "      <td>3128.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005699</td>\n",
       "      <td>0.004696</td>\n",
       "      <td>892.92</td>\n",
       "      <td>987.35</td>\n",
       "      <td>924.71</td>\n",
       "      <td>951.54</td>\n",
       "      <td>5850.2</td>\n",
       "      <td>3591.9</td>\n",
       "      <td>4988.3</td>\n",
       "      <td>4083.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>916 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0.0011806  0.0012137  0.001208  0.0012018   1071.2   1046.8   1048.8  \\\n",
       "0     0.001107   0.001119  0.001116   0.001109  1039.50  1033.20  1037.90   \n",
       "1     0.000838   0.000817  0.000813   0.000816  1474.20  1506.50  1512.10   \n",
       "2     0.000959   0.000957  0.000959   0.000958  1173.50  1181.10  1182.60   \n",
       "3     0.001199   0.001197  0.001212   0.001218   998.09  1001.80   989.75   \n",
       "4     0.001475   0.001478  0.001462   0.001484   907.20   910.03   921.85   \n",
       "..         ...        ...       ...        ...      ...      ...      ...   \n",
       "911   0.001524   0.001544  0.001554   0.001533   771.82   765.06   760.72   \n",
       "912   0.002081   0.002125  0.002143   0.002136   717.41   706.27   692.82   \n",
       "913   0.001254   0.001253  0.001270   0.001281  1184.30  1209.10  1198.60   \n",
       "914   0.001481   0.001492  0.001491   0.001518   888.70   883.39   877.48   \n",
       "915   0.001311   0.001322  0.001324   0.001325  1223.90  1234.90  1235.60   \n",
       "\n",
       "        1055   1180.7  1552.3  ...  0.0061704  0.0046729  778.89   795.98  \\\n",
       "0    1042.00  2061.90  2842.8  ...   0.005960   0.004115  690.72   744.43   \n",
       "1    1509.20  3152.70  4917.1  ...   0.005271   0.003754  871.63  1030.40   \n",
       "2    1181.20   989.97  1348.5  ...   0.005446   0.003669  761.77   836.36   \n",
       "3     984.42   930.80  1843.0  ...   0.005279   0.004436  641.78   785.93   \n",
       "4     900.22   955.55  1267.9  ...   0.012025   0.008193  665.58   725.56   \n",
       "..       ...      ...     ...  ...        ...        ...     ...      ...   \n",
       "911   767.49  1757.30  2667.9  ...   0.013590   0.009052  449.22   505.74   \n",
       "912   697.34  1442.90  1588.2  ...   0.015723   0.008687  605.75   603.61   \n",
       "913  1190.80  2033.90  2822.1  ...   0.006287   0.004550  829.15   925.68   \n",
       "914   866.00  1548.80  2111.8  ...   0.005301   0.004107  682.09   734.07   \n",
       "915  1238.50  2221.90  3128.7  ...   0.005699   0.004696  892.92   987.35   \n",
       "\n",
       "      788.88   839.12   4806.8  3260.5     3810  2836.1  \n",
       "0     709.54   766.11   5627.8  3720.7   5336.2  3671.1  \n",
       "1    1000.50  1020.10  13398.0  7915.7  11760.0  8232.1  \n",
       "2     800.78   846.97   7517.2  4942.6   6486.0  4416.6  \n",
       "3     751.50   760.29   6421.8  2951.4   3344.0  2882.6  \n",
       "4     684.40   712.31   4015.4  2846.9   3709.8  2642.7  \n",
       "..       ...      ...      ...     ...      ...     ...  \n",
       "911   481.86   525.14   6456.4  4333.4   5510.5  3652.4  \n",
       "912   527.33   604.96   1930.2  1742.7   2547.4  1486.1  \n",
       "913   873.47   902.69   6960.8  4208.7   5503.9  4354.0  \n",
       "914   688.15   697.72   3022.3  2036.6   2609.3  2124.5  \n",
       "915   924.71   951.54   5850.2  3591.9   4988.3  4083.6  \n",
       "\n",
       "[916 rows x 44 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns=df.columns[-1])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    KNeighborsClassifier(),\n",
    "    SVC(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    GaussianNB(),\n",
    "    Perceptron(),\n",
    "    MLPClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    ExtraTreesClassifier(),\n",
    "    BaggingClassifier(),\n",
    "    RidgeClassifier()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(5, shuffle=True, random_state=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - KNeighborsClassifier -> 0.5376884422110553\n",
      "Fold 1 - SVC -> 0.5767682576193214\n",
      "Fold 1 - DecisionTreeClassifier -> 0.5614532337026539\n",
      "Fold 1 - RandomForestClassifier -> 0.635127478753541\n",
      "Fold 1 - GradientBoostingClassifier -> 0.6262258335668254\n",
      "Fold 1 - GaussianNB -> 0.6455696202531646\n",
      "Fold 1 - Perceptron -> 0.44166460242754524\n",
      "Fold 1 - MLPClassifier -> 0.6008414409676571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mauriciobenjamin700/projects/course/ufpi/8-periodo/sistemas-inteligentes/.venv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - AdaBoostClassifier -> 0.5746707761277668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mauriciobenjamin700/projects/course/ufpi/8-periodo/sistemas-inteligentes/.venv/lib/python3.12/site-packages/sklearn/discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - QuadraticDiscriminantAnalysis -> 0.7139767504731008\n",
      "Fold 1 - LinearDiscriminantAnalysis -> 0.5860517435320585\n",
      "Fold 1 - ExtraTreesClassifier -> 0.666108319374651\n",
      "Fold 1 - BaggingClassifier -> 0.6090651558073654\n",
      "Fold 1 - RidgeClassifier -> 0.5503162737205289\n",
      "Fold 2 - KNeighborsClassifier -> 0.5250608272506083\n",
      "Fold 2 - SVC -> 0.486610558530987\n",
      "Fold 2 - DecisionTreeClassifier -> 0.5327205077697527\n",
      "Fold 2 - RandomForestClassifier -> 0.5429054870679236\n",
      "Fold 2 - GradientBoostingClassifier -> 0.600187265917603\n",
      "Fold 2 - GaussianNB -> 0.48150700666207213\n",
      "Fold 2 - Perceptron -> 0.30742358078602616\n",
      "Fold 2 - MLPClassifier -> 0.5166402535657686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mauriciobenjamin700/projects/course/ufpi/8-periodo/sistemas-inteligentes/.venv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 - AdaBoostClassifier -> 0.5605187319884726\n",
      "Fold 2 - QuadraticDiscriminantAnalysis -> 0.5060188224994528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mauriciobenjamin700/projects/course/ufpi/8-periodo/sistemas-inteligentes/.venv/lib/python3.12/site-packages/sklearn/discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 - LinearDiscriminantAnalysis -> 0.486610558530987\n",
      "Fold 2 - ExtraTreesClassifier -> 0.531219980787704\n",
      "Fold 2 - BaggingClassifier -> 0.531219980787704\n",
      "Fold 2 - RidgeClassifier -> 0.5234375\n",
      "Fold 3 - KNeighborsClassifier -> 0.4801612755429304\n",
      "Fold 3 - SVC -> 0.5823280078252364\n",
      "Fold 3 - DecisionTreeClassifier -> 0.5179709406066786\n",
      "Fold 3 - RandomForestClassifier -> 0.5678866587957496\n",
      "Fold 3 - GradientBoostingClassifier -> 0.5636623748211731\n",
      "Fold 3 - GaussianNB -> 0.5507930513595166\n",
      "Fold 3 - Perceptron -> 0.2932179823883825\n",
      "Fold 3 - MLPClassifier -> 0.46750727449078566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mauriciobenjamin700/projects/course/ufpi/8-periodo/sistemas-inteligentes/.venv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 - AdaBoostClassifier -> 0.5136992577659671\n",
      "Fold 3 - QuadraticDiscriminantAnalysis -> 0.6473308922721142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mauriciobenjamin700/projects/course/ufpi/8-periodo/sistemas-inteligentes/.venv/lib/python3.12/site-packages/sklearn/discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 - LinearDiscriminantAnalysis -> 0.5572905212227842\n",
      "Fold 3 - ExtraTreesClassifier -> 0.5814855324649497\n",
      "Fold 3 - BaggingClassifier -> 0.5062632491809598\n",
      "Fold 3 - RidgeClassifier -> 0.5316568376543898\n",
      "Fold 4 - KNeighborsClassifier -> 0.4301094403416674\n",
      "Fold 4 - SVC -> 0.4380038387715931\n",
      "Fold 4 - DecisionTreeClassifier -> 0.437810161480898\n",
      "Fold 4 - RandomForestClassifier -> 0.5731969860064585\n",
      "Fold 4 - GradientBoostingClassifier -> 0.5731969860064585\n",
      "Fold 4 - GaussianNB -> 0.4760862243179522\n",
      "Fold 4 - Perceptron -> 0.23966761425759897\n",
      "Fold 4 - MLPClassifier -> 0.2641430948419301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mauriciobenjamin700/projects/course/ufpi/8-periodo/sistemas-inteligentes/.venv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 - AdaBoostClassifier -> 0.5278049648545244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mauriciobenjamin700/projects/course/ufpi/8-periodo/sistemas-inteligentes/.venv/lib/python3.12/site-packages/sklearn/discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 - QuadraticDiscriminantAnalysis -> 0.4795311557355856\n",
      "Fold 4 - LinearDiscriminantAnalysis -> 0.4153354632587859\n",
      "Fold 4 - ExtraTreesClassifier -> 0.5603701396921434\n",
      "Fold 4 - BaggingClassifier -> 0.5032834252692409\n",
      "Fold 4 - RidgeClassifier -> 0.36877894944318523\n",
      "Fold 5 - KNeighborsClassifier -> 0.5481481481481482\n",
      "Fold 5 - SVC -> 0.6205943331029717\n",
      "Fold 5 - DecisionTreeClassifier -> 0.5480761570939219\n",
      "Fold 5 - RandomForestClassifier -> 0.7121132669113791\n",
      "Fold 5 - GradientBoostingClassifier -> 0.6856750257643421\n",
      "Fold 5 - GaussianNB -> 0.5793103448275863\n",
      "Fold 5 - Perceptron -> 0.6197007481296758\n",
      "Fold 5 - MLPClassifier -> 0.3361889326232924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mauriciobenjamin700/projects/course/ufpi/8-periodo/sistemas-inteligentes/.venv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 - AdaBoostClassifier -> 0.6170586758181971\n",
      "Fold 5 - QuadraticDiscriminantAnalysis -> 0.6743772241992882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mauriciobenjamin700/projects/course/ufpi/8-periodo/sistemas-inteligentes/.venv/lib/python3.12/site-packages/sklearn/discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 - LinearDiscriminantAnalysis -> 0.6558209516644724\n",
      "Fold 5 - ExtraTreesClassifier -> 0.6670709520921771\n",
      "Fold 5 - BaggingClassifier -> 0.6611409928577727\n",
      "Fold 5 - RidgeClassifier -> 0.6842407975460123\n"
     ]
    }
   ],
   "source": [
    "def kappa_cross_val(models: list[RandomForestClassifier, GradientBoostingClassifier], X: pd.Series, y: pd.Series):\n",
    "    kappas = {}\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kfold.split(X)):\n",
    "        x_train, x_test = np.array(X)[train_index], np.array(X)[test_index]\n",
    "        y_train, y_test = np.array(y)[train_index], np.array(y)[test_index]\n",
    "\n",
    "        for model in models:\n",
    "            model.fit(x_train, y_train)\n",
    "            y_pred = model.predict(x_test)\n",
    "            model_name = model.__class__.__name__\n",
    "            kappa = cohen_kappa_score(y_test, y_pred)\n",
    "            print(f\"Fold {i+1} - {model_name} -> {kappa}\")\n",
    "            kappas[model_name] = kappas.get(model_name, 0) + kappa\n",
    "\n",
    "    return kappas\n",
    "\n",
    "kappas = kappa_cross_val(models, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier -> 0.6062459755070104\n",
      "GradientBoostingClassifier -> 0.6097894972152804\n",
      "QuadraticDiscriminantAnalysis -> 0.6042469690359084\n",
      "ExtraTreesClassifier -> 0.6012509848823251\n"
     ]
    }
   ],
   "source": [
    "for model_name, kappa in kappas.items():\n",
    "    mean_kappa = kappa/5\n",
    "    if mean_kappa > 0.6:\n",
    "        print(f\"{model_name} -> {kappa/5}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_split=2, min_samples_leaf=1, max_features='sqrt', bootstrap=True, criterion='gini', random_state=19, class_weight='balanced')\n",
    "gbc = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, min_samples_split=2, min_samples_leaf=1, random_state=19)\n",
    "qda = QuadraticDiscriminantAnalysis(reg_param=0.0, store_covariance=False, tol=1e-4)\n",
    "etc = ExtraTreesClassifier(n_estimators=100, max_depth=None, min_samples_split=2, min_samples_leaf=1, max_features='sqrt', random_state=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [rf, gbc, qda, etc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - RandomForestClassifier -> 0.6234829240756421\n",
      "Fold 1 - GradientBoostingClassifier -> 0.6262258335668254\n",
      "Fold 1 - QuadraticDiscriminantAnalysis -> 0.7139767504731008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mauriciobenjamin700/projects/course/ufpi/8-periodo/sistemas-inteligentes/.venv/lib/python3.12/site-packages/sklearn/discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - ExtraTreesClassifier -> 0.666108319374651\n",
      "Fold 2 - RandomForestClassifier -> 0.5487950369840133\n",
      "Fold 2 - GradientBoostingClassifier -> 0.600187265917603\n",
      "Fold 2 - QuadraticDiscriminantAnalysis -> 0.5060188224994528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mauriciobenjamin700/projects/course/ufpi/8-periodo/sistemas-inteligentes/.venv/lib/python3.12/site-packages/sklearn/discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 - ExtraTreesClassifier -> 0.5732133933033483\n",
      "Fold 3 - RandomForestClassifier -> 0.5545711225781327\n",
      "Fold 3 - GradientBoostingClassifier -> 0.5189368123843832\n",
      "Fold 3 - QuadraticDiscriminantAnalysis -> 0.6473308922721142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mauriciobenjamin700/projects/course/ufpi/8-periodo/sistemas-inteligentes/.venv/lib/python3.12/site-packages/sklearn/discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 - ExtraTreesClassifier -> 0.5678866587957496\n",
      "Fold 4 - RandomForestClassifier -> 0.5927299703264095\n",
      "Fold 4 - GradientBoostingClassifier -> 0.5603701396921434\n",
      "Fold 4 - QuadraticDiscriminantAnalysis -> 0.4795311557355856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mauriciobenjamin700/projects/course/ufpi/8-periodo/sistemas-inteligentes/.venv/lib/python3.12/site-packages/sklearn/discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 - ExtraTreesClassifier -> 0.5793103448275863\n",
      "Fold 5 - RandomForestClassifier -> 0.6481384373361301\n",
      "Fold 5 - GradientBoostingClassifier -> 0.6910349485058247\n",
      "Fold 5 - QuadraticDiscriminantAnalysis -> 0.6743772241992882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mauriciobenjamin700/projects/course/ufpi/8-periodo/sistemas-inteligentes/.venv/lib/python3.12/site-packages/sklearn/discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 - ExtraTreesClassifier -> 0.6934132792522705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'RandomForestClassifier': np.float64(2.967717491300328),\n",
       " 'GradientBoostingClassifier': np.float64(2.9967550000667793),\n",
       " 'QuadraticDiscriminantAnalysis': np.float64(3.0212348451795417),\n",
       " 'ExtraTreesClassifier': np.float64(3.079931995553606)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kappa_cross_val(models, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kappa: 0.6912751677852349\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividir os dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=19)\n",
    "\n",
    "# Aplicar SMOTE para balancear as classes\n",
    "smote = SMOTE(random_state=19)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Criar e treinar o modelo de Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=19)\n",
    "rf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Fazer previsões\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Calcular a métrica Kappa\n",
    "kappa = cohen_kappa_score(y_test, y_pred)\n",
    "print(f\"Kappa: {kappa}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - RandomForestClassifier -> 0.6234829240756421\n",
      "Fold 1 - GradientBoostingClassifier -> 0.6262258335668254\n",
      "Fold 1 - QuadraticDiscriminantAnalysis -> 0.7139767504731008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mauriciobenjamin700/projects/course/ufpi/8-periodo/sistemas-inteligentes/.venv/lib/python3.12/site-packages/sklearn/discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - ExtraTreesClassifier -> 0.666108319374651\n",
      "Fold 2 - RandomForestClassifier -> 0.5487950369840133\n",
      "Fold 2 - GradientBoostingClassifier -> 0.600187265917603\n",
      "Fold 2 - QuadraticDiscriminantAnalysis -> 0.5060188224994528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mauriciobenjamin700/projects/course/ufpi/8-periodo/sistemas-inteligentes/.venv/lib/python3.12/site-packages/sklearn/discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 - ExtraTreesClassifier -> 0.5732133933033483\n",
      "Fold 3 - RandomForestClassifier -> 0.5545711225781327\n",
      "Fold 3 - GradientBoostingClassifier -> 0.5189368123843832\n",
      "Fold 3 - QuadraticDiscriminantAnalysis -> 0.6473308922721142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mauriciobenjamin700/projects/course/ufpi/8-periodo/sistemas-inteligentes/.venv/lib/python3.12/site-packages/sklearn/discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 - ExtraTreesClassifier -> 0.5678866587957496\n",
      "Fold 4 - RandomForestClassifier -> 0.5927299703264095\n",
      "Fold 4 - GradientBoostingClassifier -> 0.5603701396921434\n",
      "Fold 4 - QuadraticDiscriminantAnalysis -> 0.4795311557355856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mauriciobenjamin700/projects/course/ufpi/8-periodo/sistemas-inteligentes/.venv/lib/python3.12/site-packages/sklearn/discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 - ExtraTreesClassifier -> 0.5793103448275863\n",
      "Fold 5 - RandomForestClassifier -> 0.6481384373361301\n",
      "Fold 5 - GradientBoostingClassifier -> 0.6910349485058247\n",
      "Fold 5 - QuadraticDiscriminantAnalysis -> 0.6743772241992882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mauriciobenjamin700/projects/course/ufpi/8-periodo/sistemas-inteligentes/.venv/lib/python3.12/site-packages/sklearn/discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 - ExtraTreesClassifier -> 0.6934132792522705\n"
     ]
    }
   ],
   "source": [
    "def kappa_smote_cross_val(models: list[RandomForestClassifier, GradientBoostingClassifier], X: pd.Series, y: pd.Series):\n",
    "    kappas = {}\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kfold.split(X)):\n",
    "        x_train, x_test = np.array(X)[train_index], np.array(X)[test_index]\n",
    "        y_train, y_test = np.array(y)[train_index], np.array(y)[test_index]\n",
    "\n",
    "        smote = SMOTE(random_state=19)\n",
    "\n",
    "        X_train_resampled, y_train_resampled = smote.fit_resample(x_train, y_train)\n",
    "\n",
    "        for model in models:\n",
    "            model.fit(X_train_resampled, y_train_resampled)\n",
    "            y_pred = model.predict(x_test)\n",
    "            model_name = model.__class__.__name__\n",
    "            kappa = cohen_kappa_score(y_test, y_pred)\n",
    "            print(f\"Fold {i+1} - {model_name} -> {kappa}\")\n",
    "            kappas[model_name] = kappas.get(model_name, 0) + kappa\n",
    "\n",
    "    return kappas\n",
    "\n",
    "kappas = kappa_cross_val(models, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Realizar o Grid Search com validação cruzada estratificada\u001b[39;00m\n\u001b[1;32m     25\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mxgb, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_resampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_resampled\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Melhor modelo encontrado pelo Grid Search\u001b[39;00m\n\u001b[1;32m     29\u001b[0m best_model \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[0;32m~/projects/course/ufpi/8-periodo/sistemas-inteligentes/.venv/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/course/ufpi/8-periodo/sistemas-inteligentes/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1015\u001b[0m     )\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1019\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/projects/course/ufpi/8-periodo/sistemas-inteligentes/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1573\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1572\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1573\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/course/ufpi/8-periodo/sistemas-inteligentes/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:965\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    960\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    961\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    962\u001b[0m         )\n\u001b[1;32m    963\u001b[0m     )\n\u001b[0;32m--> 965\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    984\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    987\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    988\u001b[0m     )\n",
      "File \u001b[0;32m~/projects/course/ufpi/8-periodo/sistemas-inteligentes/.venv/lib/python3.12/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/course/ufpi/8-periodo/sistemas-inteligentes/.venv/lib/python3.12/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/course/ufpi/8-periodo/sistemas-inteligentes/.venv/lib/python3.12/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/course/ufpi/8-periodo/sistemas-inteligentes/.venv/lib/python3.12/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "# Dividir os dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=19)\n",
    "\n",
    "# Aplicar SMOTE para balancear as classes\n",
    "smote = SMOTE(random_state=19)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Definir o modelo e os hiperparâmetros para o Grid Search\n",
    "xgb = XGBClassifier(random_state=19)\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200, 500, 1000,2000],\n",
    "    'learning_rate': [0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "    'max_depth': [3, 5, 7, 9, 11, 13, 15],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Realizar o Grid Search com validação cruzada estratificada\n",
    "grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Melhor modelo encontrado pelo Grid Search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Fazer previsões\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calcular a métrica Kappa\n",
    "kappa = cohen_kappa_score(y_test, y_pred)\n",
    "print(f\"Melhor Kappa: {kappa}\")\n",
    "print(f\"Melhores Hiperparâmetros: {grid_search.best_params_}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
